#!/usr/bin/env python3
"""
Reconstruct a complete Stable Diffusion checkpoint from separate ONNX component files.

This script takes the ONNX files generated by convert_to_onnx.py and reconstructs
a complete .safetensors checkpoint that can be loaded by Stable Diffusion WebUI.

Usage:
    python reconstruct_checkpoint_from_onnx.py \\
        --onnx-dir Cache/test/ \\
        --output checkpoint_reconstructed.safetensors \\
        --base-name indigoFurryMix_v100Anime

Note: This requires the original checkpoint to extract proper weight names,
      or uses the diffusers library to load ONNX weights into proper pipeline components.
"""

import argparse
import sys
from pathlib import Path
from typing import Dict, Optional

import torch
from safetensors.torch import save_file, load_file
from diffusers import StableDiffusionPipeline, UNet2DConditionModel, AutoencoderKL
from transformers import CLIPTextModel


def load_onnx_as_state_dict(onnx_path: Path) -> Dict[str, torch.Tensor]:
    """Load ONNX model and extract weights."""
    import onnx
    from onnx import numpy_helper

    model = onnx.load(str(onnx_path), load_external_data=True)
    state_dict = {}

    for initializer in model.graph.initializer:
        array = numpy_helper.to_array(initializer)
        tensor = torch.from_numpy(array)
        name = initializer.name
        state_dict[name] = tensor

    return state_dict


def reconstruct_from_diffusers(
    unet_onnx: Path,
    vae_decoder_onnx: Path,
    vae_encoder_onnx: Optional[Path],
    clip_onnx: Path,
    original_checkpoint: Optional[Path] = None,
) -> Dict[str, torch.Tensor]:
    """
    Reconstruct checkpoint by loading ONNX weights into diffusers models.

    This approach:
    1. Creates fresh diffusers model instances
    2. Attempts to map ONNX weights to model state dicts
    3. Merges them into a single checkpoint format
    """
    print("WARNING: Direct ONNX -> checkpoint reconstruction is complex.")
    print("The ONNX export process changes weight names and structure.")
    print("\nRECOMMENDED SOLUTION:")
    print("  1. Keep your original .safetensors checkpoint")
    print("  2. Use ONNX files only for inference with ONNX Runtime or TensorRT")
    print("  3. Do not convert back to checkpoint format")
    print("\nIf you must reconstruct, you'll need to:")
    print("  - Manually map ONNX node names to PyTorch state dict keys")
    print("  - This is error-prone and may not work for all models")

    raise NotImplementedError(
        "ONNX to checkpoint reconstruction is not supported.\n"
        "Please use your original checkpoint file instead."
    )


def create_diffusers_pipeline_from_onnx(
    onnx_dir: Path,
    base_name: str,
    output_dir: Path,
) -> None:
    """
    Alternative: Create a diffusers-format pipeline directory from ONNX files.

    This creates separate component directories that can be loaded by diffusers:
    - unet/
    - vae/
    - text_encoder/
    - etc.
    """
    print(f"\n{'='*80}")
    print("Creating diffusers-format pipeline from ONNX components")
    print(f"{'='*80}\n")

    # Find ONNX files
    unet_onnx = onnx_dir / f"unet_{base_name}.onnx"
    vae_decoder_onnx = onnx_dir / f"vae_decoder_{base_name}.onnx"
    vae_encoder_onnx = onnx_dir / f"vae_encoder_{base_name}.onnx"
    clip_onnx = onnx_dir / f"clip_text_{base_name}.onnx"

    missing = []
    for name, path in [
        ("UNet", unet_onnx),
        ("VAE Decoder", vae_decoder_onnx),
        ("CLIP Text", clip_onnx),
    ]:
        if not path.exists():
            missing.append(f"{name}: {path}")

    if missing:
        print("ERROR: Missing required ONNX files:")
        for m in missing:
            print(f"  - {m}")
        print("\nPlease run convert_to_onnx.py first to generate all components.")
        sys.exit(1)

    print("Found ONNX components:")
    print(f"  ✓ UNet: {unet_onnx}")
    print(f"  ✓ VAE Decoder: {vae_decoder_onnx}")
    if vae_encoder_onnx.exists():
        print(f"  ✓ VAE Encoder: {vae_encoder_onnx}")
    print(f"  ✓ CLIP Text: {clip_onnx}")

    print("\n" + "="*80)
    print("IMPORTANT: ONNX to checkpoint conversion is NOT RECOMMENDED")
    print("="*80)
    print("\nThe ONNX export process:")
    print("  1. Changes weight names (graph node names ≠ state dict keys)")
    print("  2. May optimize/fuse operations")
    print("  3. May quantize weights")
    print("  4. Loses metadata and configuration")
    print("\nThis means:")
    print("  ✗ Cannot reliably reconstruct original checkpoint")
    print("  ✗ Weight names don't match expected PyTorch format")
    print("  ✗ May be missing weights or have extra optimized weights")
    print("\nYou have 2 options:")
    print("\n  Option 1 (RECOMMENDED): Use your original checkpoint")
    print("    - Keep the original .safetensors file")
    print("    - Use ONNX files only for ONNX Runtime/TensorRT inference")
    print("\n  Option 2: Use ONNX files directly")
    print("    - Load with onnxruntime.InferenceSession()")
    print("    - Integrate into a custom inference pipeline")
    print("    - This is what ONNX export is designed for")
    print("\n" + "="*80 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description="Reconstruct Stable Diffusion checkpoint from ONNX components",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
WARNING: This operation is NOT RECOMMENDED and may not work correctly.

The ONNX export process fundamentally changes the model structure and weight names.
Reconstructing a working checkpoint from ONNX files is extremely difficult and error-prone.

RECOMMENDED SOLUTION:
  1. Keep your original .safetensors checkpoint file
  2. Use ONNX files only for inference (ONNX Runtime, TensorRT)
  3. Never try to convert ONNX back to checkpoint format

If you've lost the original checkpoint, you'll need to re-download it.
The ONNX files cannot be reliably converted back to a working checkpoint.

Example (showing why this doesn't work):
  python reconstruct_checkpoint_from_onnx.py \\
      --onnx-dir Cache/test/ \\
      --output checkpoint.safetensors \\
      --base-name indigoFurryMix_v100Anime
        """
    )

    parser.add_argument(
        '--onnx-dir',
        type=str,
        required=True,
        help='Directory containing ONNX component files'
    )

    parser.add_argument(
        '--output',
        type=str,
        required=True,
        help='Output checkpoint file path (.safetensors)'
    )

    parser.add_argument(
        '--base-name',
        type=str,
        required=True,
        help='Base name of the model (e.g., "indigoFurryMix_v100Anime")'
    )

    parser.add_argument(
        '--original-checkpoint',
        type=str,
        default=None,
        help='Path to original checkpoint (for reference weight names)'
    )

    args = parser.parse_args()

    onnx_dir = Path(args.onnx_dir)
    output_path = Path(args.output)

    if not onnx_dir.exists():
        print(f"ERROR: ONNX directory not found: {onnx_dir}")
        sys.exit(1)

    # Show the explanation
    create_diffusers_pipeline_from_onnx(
        onnx_dir=onnx_dir,
        base_name=args.base_name,
        output_dir=output_path.parent,
    )

    print("\nScript stopped: ONNX to checkpoint reconstruction is not supported.")
    print("\nPlease use one of the recommended solutions above.")
    sys.exit(1)


if __name__ == '__main__':
    main()
